{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "146118a3-2d05-47e2-ad5c-24eb9ad09cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import time\n",
    "from PMTK.sampling.preferences_sampler import *\n",
    "from PMTK.pref.preferences import *\n",
    "from PMTK.utility.utility_solver import *\n",
    "from PMTK.sampling.subset_samplers import *\n",
    "from PMTK.utility.subset_finder import *\n",
    "from PMTK.sampling.gibbs import *\n",
    "from PMTK.data.film_dataset import *\n",
    "from PMTK.sampling.decider import *\n",
    "from PMTK.utility import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35c7879e-64d7-4c47-ba5c-94264bc4da83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_approx_theta(prf, init_theta = None):\n",
    "    connivents = []\n",
    "    if not init_theta:\n",
    "        init_theta = [EMPTY_SET]\n",
    "    theta = init_theta\n",
    "    min_k = 1\n",
    "    c  = get_connivent(theta, prf)\n",
    "    while c:\n",
    "        if not c in connivents:\n",
    "            connivents.append(c)\n",
    "        cit = get_candidate_iterator(c)\n",
    "        skey = sorted(cit.keys())[0]\n",
    "        b = False\n",
    "        for k in cit:\n",
    "            if b:\n",
    "                break\n",
    "            for i in cit[k]:\n",
    "                for t in i:\n",
    "                    b = False or check_connivence_resolution(c, t)\n",
    "                    if not t in theta and check_connivence_resolution(c, t):\n",
    "                        theta.append(t)\n",
    "        c  = get_connivent(theta, prf)\n",
    "    a = additivity(theta)\n",
    "    for c_i in connivents:\n",
    "        cit = get_candidate_iterator(c_i)\n",
    "        for k in cit:\n",
    "            if k > a:\n",
    "                break\n",
    "            for i in cit[k]:\n",
    "                for t in i:\n",
    "                    if not t in theta and check_connivence_resolution(c_i,t):\n",
    "                        theta.append(t)\n",
    "    \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b90af2ae-d461-447c-8ddd-dec025c683b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_from_mult_thetas(thetas,p, subsets):\n",
    "    mdls = [utility_polyhedron(p.items, t, p) for t in thetas]\n",
    "    prf = Preferences(p.items)\n",
    "    for i_1 in range(len(subsets)):\n",
    "        s_1 = subsets[i_1]\n",
    "        for i_2 in range(i_1 + 1, len(subsets)):\n",
    "            s_2 = subsets[i_2]\n",
    "            r = [ordinal_dominance(s_1, s_2, mdl) for mdl in mdls]\n",
    "            if all(i == \"SUP\" for i in r):\n",
    "                prf.add_preference(s_1, s_2)\n",
    "            elif all(i == \"INF\" for i in r):\n",
    "                prf.add_preference(s_2, s_1)\n",
    "            elif all(i == \"EQ\" for i in r):\n",
    "                prf.add_indifference(s_1,s_2)\n",
    "    return prf\n",
    "\n",
    "def predict_from_theta(theta, p, subsets):\n",
    "    mdl = utility_polyhedron(p.items, theta, p)\n",
    "    prf = ordinal_peferences(p.items, subsets, mdl)\n",
    "    return prf\n",
    "\n",
    "def complete_theta(theta):\n",
    "    t2 = []\n",
    "    for x in theta:\n",
    "        for s in get_all_k_sets(x, len(x)):\n",
    "            if not s in t2:\n",
    "                t2.append(s)\n",
    "    return t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61b95480-0f4f-468e-9692-2aa5642b560c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ACR(prf, decider):\n",
    "    C = 0\n",
    "    W = 0\n",
    "    T = len(prf.preferred)\n",
    "    for x,y in prf.preferred:\n",
    "        if decider(x) > decider(y):\n",
    "            C += 1\n",
    "        elif decider(x) < decider(y):\n",
    "            W += 1\n",
    "    return C,W,T\n",
    "\n",
    "def intersect_per_union(prf_1, prf_2):\n",
    "    intersection = prf_1.intersection(prf_2)\n",
    "    un = prf_1 + prf_2\n",
    "    return len(intersection) / len(un)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549c88e7-5f3b-4c02-8b64-cec8c6ad95ba",
   "metadata": {},
   "source": [
    "## Listes des $\\theta$ expérimentés:\n",
    "\n",
    "- Union des $\\theta$ qui minimisent lexicographiquement (additivité, taille).\n",
    "- Un des $\\theta$ qui minimisent lexicographiquement (additivité, taille).\n",
    "\n",
    "- Union des $\\theta$ qui minimisent lexicographiquement (additivité, taille, somme des tailles).\n",
    "- Un des $\\theta$ qui minimisent lexicographiquement (additivité, taille, somme des tailles).\n",
    "\n",
    "- Union des $\\theta$ qui minimisent l'additivité.\n",
    "- Un des $\\theta$ qui minimisent l'additivité.\n",
    "\n",
    "- Union des $\\theta$ qui minimisent la variance.\n",
    "- Un des $\\theta$ qui minimisent la variance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1414b2c3-7901-435a-b9c3-a0c477da2e9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(4,), (1,), (2, 4), (3, 4), (2, 3), (0, 3), (0,)],\n",
       " [(4,), (1,), (2, 4), (3, 4), (3,), (0, 3), (0,)],\n",
       " [(4,), (1,), (2, 4), (3, 4), (3,), (0, 3), (0, 4)],\n",
       " [(4,), (1,), (2, 4), (3, 4), (2, 3), (0, 3), (0, 4)],\n",
       " [(4,), (1,), (2, 4), (3, 4), (2, 3), (0, 3), (0, 2)],\n",
       " [(4,), (1,), (2, 4), (3, 4), (3,), (0, 3), (0, 2)]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_items = 5\n",
    "density = 0.4\n",
    "items = np.arange(n_items)\n",
    "\n",
    "theta = [EMPTY_SET]\n",
    "prf = sample_preferences_from_order(items, density*(2**(n_items+1)), indifference_rate= 0)\n",
    "\n",
    "t_heuristic = build_approx_theta(prf, [EMPTY_SET])\n",
    "t_mins = get_kernels_lex2(prf,t_heuristic)\n",
    "t_mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe7f23a4-ee1e-4a62-a191-3a9d81d36d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(4,), (1,), (2, 4), (3, 4), (3,), (0, 3), (0,)]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_mins = get_kernels_lex3(prf,t_heuristic)\n",
    "t_mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6541e8e7-8379-4015-83c2-3e140eaf4daa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(4,), (1,), (2, 4), (3, 4), (3,), (0, 3), (0,)]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_mins = get_kernels_variance(prf,t_heuristic)\n",
    "t_mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8373a76-a6ec-4d43-8825-ed0ba29201b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lex2 took 0.12\n",
      "Lex3 took 0.12\n",
      "Var took 0.08\n",
      "repetition = 0, b = 2, srep = 0\n",
      "repetition = 0, b = 2, srep = 1\n",
      "repetition = 0, b = 2, srep = 2\n",
      "repetition = 0, b = 2, srep = 3\n",
      "repetition = 0, b = 2, srep = 4\n",
      "Lex2 took 0.31\n",
      "Lex3 took 0.34\n",
      "Var took 0.28\n",
      "repetition = 0, b = 3, srep = 0\n",
      "repetition = 0, b = 3, srep = 1\n",
      "repetition = 0, b = 3, srep = 2\n",
      "repetition = 0, b = 3, srep = 3\n",
      "repetition = 0, b = 3, srep = 4\n",
      "Lex2 took 0.36\n",
      "Lex3 took 0.38\n",
      "Var took 0.33\n",
      "repetition = 0, b = 4, srep = 0\n",
      "repetition = 0, b = 4, srep = 1\n",
      "repetition = 0, b = 4, srep = 2\n",
      "repetition = 0, b = 4, srep = 3\n",
      "repetition = 0, b = 4, srep = 4\n",
      "Lex2 took 0.25\n",
      "Lex3 took 0.34\n",
      "Var took 0.24\n",
      "repetition = 0, b = 5, srep = 0\n",
      "repetition = 0, b = 5, srep = 1\n",
      "repetition = 0, b = 5, srep = 2\n",
      "repetition = 0, b = 5, srep = 3\n",
      "repetition = 0, b = 5, srep = 4\n",
      "Lex2 took 0.14\n",
      "Lex3 took 0.14\n",
      "Var took 0.08\n",
      "repetition = 0, b = 6, srep = 0\n",
      "repetition = 0, b = 6, srep = 1\n",
      "repetition = 0, b = 6, srep = 2\n",
      "repetition = 0, b = 6, srep = 3\n",
      "repetition = 0, b = 6, srep = 4\n",
      "Lex2 took 0.12\n",
      "Lex3 took 0.13\n",
      "Var took 0.09\n",
      "repetition = 0, b = 7, srep = 0\n",
      "repetition = 0, b = 7, srep = 1\n",
      "repetition = 0, b = 7, srep = 2\n",
      "repetition = 0, b = 7, srep = 3\n",
      "repetition = 0, b = 7, srep = 4\n",
      "Lex2 took 0.19\n",
      "Lex3 took 0.17\n",
      "Var took 0.12\n",
      "repetition = 0, b = 8, srep = 0\n",
      "repetition = 0, b = 8, srep = 1\n",
      "repetition = 0, b = 8, srep = 2\n",
      "repetition = 0, b = 8, srep = 3\n",
      "repetition = 0, b = 8, srep = 4\n",
      "Lex2 took 0.13\n",
      "Lex3 took 0.13\n",
      "Var took 0.09\n",
      "repetition = 0, b = 9, srep = 0\n",
      "repetition = 0, b = 9, srep = 1\n",
      "repetition = 0, b = 9, srep = 2\n",
      "repetition = 0, b = 9, srep = 3\n",
      "repetition = 0, b = 9, srep = 4\n",
      "Lex2 took 0.14\n",
      "Lex3 took 0.14\n",
      "Var took 0.12\n",
      "repetition = 0, b = 10, srep = 0\n",
      "repetition = 0, b = 10, srep = 1\n",
      "repetition = 0, b = 10, srep = 2\n",
      "repetition = 0, b = 10, srep = 3\n",
      "repetition = 0, b = 10, srep = 4\n",
      "Lex2 took 0.16\n",
      "Lex3 took 0.17\n",
      "Var took 0.16\n",
      "repetition = 0, b = 11, srep = 0\n",
      "repetition = 0, b = 11, srep = 1\n",
      "repetition = 0, b = 11, srep = 2\n",
      "repetition = 0, b = 11, srep = 3\n",
      "repetition = 0, b = 11, srep = 4\n",
      "Lex2 took 0.18\n",
      "Lex3 took 0.19\n",
      "Var took 0.17\n",
      "repetition = 0, b = 12, srep = 0\n",
      "repetition = 0, b = 12, srep = 1\n",
      "repetition = 0, b = 12, srep = 2\n",
      "repetition = 0, b = 12, srep = 3\n",
      "repetition = 0, b = 12, srep = 4\n",
      "Lex2 took 0.20\n",
      "Lex3 took 0.22\n",
      "Var took 0.16\n",
      "repetition = 0, b = 13, srep = 0\n",
      "repetition = 0, b = 13, srep = 1\n",
      "repetition = 0, b = 13, srep = 2\n",
      "repetition = 0, b = 13, srep = 3\n",
      "repetition = 0, b = 13, srep = 4\n",
      "Lex2 took 0.17\n",
      "Lex3 took 0.17\n",
      "Var took 0.13\n",
      "repetition = 0, b = 14, srep = 0\n",
      "repetition = 0, b = 14, srep = 1\n",
      "repetition = 0, b = 14, srep = 2\n",
      "repetition = 0, b = 14, srep = 3\n",
      "repetition = 0, b = 14, srep = 4\n",
      "Lex2 took 0.18\n",
      "Lex3 took 0.17\n",
      "Var took 0.13\n",
      "repetition = 0, b = 15, srep = 0\n",
      "repetition = 0, b = 15, srep = 1\n",
      "repetition = 0, b = 15, srep = 2\n",
      "repetition = 0, b = 15, srep = 3\n",
      "repetition = 0, b = 15, srep = 4\n",
      "Lex2 took 0.16\n",
      "Lex3 took 0.19\n",
      "Var took 0.15\n",
      "repetition = 0, b = 16, srep = 0\n",
      "repetition = 0, b = 16, srep = 1\n",
      "repetition = 0, b = 16, srep = 2\n",
      "repetition = 0, b = 16, srep = 3\n",
      "repetition = 0, b = 16, srep = 4\n",
      "Lex2 took 0.37\n",
      "Lex3 took 0.51\n",
      "Var took 0.24\n",
      "repetition = 0, b = 17, srep = 0\n",
      "repetition = 0, b = 17, srep = 1\n",
      "repetition = 0, b = 17, srep = 2\n",
      "repetition = 0, b = 17, srep = 3\n",
      "repetition = 0, b = 17, srep = 4\n",
      "Lex2 took 1.62\n",
      "Lex3 took 0.46\n",
      "Var took 0.25\n",
      "repetition = 0, b = 18, srep = 0\n",
      "repetition = 0, b = 18, srep = 1\n",
      "repetition = 0, b = 18, srep = 2\n",
      "repetition = 0, b = 18, srep = 3\n",
      "repetition = 0, b = 18, srep = 4\n",
      "Lex2 took 4.12\n",
      "Lex3 took 0.56\n",
      "Var took 0.41\n",
      "repetition = 0, b = 19, srep = 0\n",
      "repetition = 0, b = 19, srep = 1\n",
      "repetition = 0, b = 19, srep = 2\n",
      "repetition = 0, b = 19, srep = 3\n",
      "repetition = 0, b = 19, srep = 4\n",
      "Lex2 took 1.54\n",
      "Lex3 took 0.43\n",
      "Var took 0.29\n",
      "repetition = 0, b = 20, srep = 0\n",
      "repetition = 0, b = 20, srep = 1\n",
      "repetition = 0, b = 20, srep = 2\n",
      "repetition = 0, b = 20, srep = 3\n",
      "repetition = 0, b = 20, srep = 4\n",
      "Lex2 took 1.79\n",
      "Lex3 took 0.48\n",
      "Var took 0.38\n",
      "repetition = 0, b = 21, srep = 0\n",
      "repetition = 0, b = 21, srep = 1\n",
      "repetition = 0, b = 21, srep = 2\n",
      "repetition = 0, b = 21, srep = 3\n",
      "repetition = 0, b = 21, srep = 4\n",
      "Lex2 took 1.75\n",
      "Lex3 took 0.44\n",
      "Var took 0.31\n",
      "repetition = 0, b = 22, srep = 0\n",
      "repetition = 0, b = 22, srep = 1\n",
      "repetition = 0, b = 22, srep = 2\n",
      "repetition = 0, b = 22, srep = 3\n",
      "repetition = 0, b = 22, srep = 4\n",
      "Lex2 took 0.87\n",
      "Lex3 took 0.51\n",
      "Var took 0.36\n",
      "repetition = 0, b = 23, srep = 0\n",
      "repetition = 0, b = 23, srep = 1\n",
      "repetition = 0, b = 23, srep = 2\n",
      "repetition = 0, b = 23, srep = 3\n",
      "repetition = 0, b = 23, srep = 4\n"
     ]
    }
   ],
   "source": [
    "n_items = 5\n",
    "items = np.arange(n_items)\n",
    "ground_truth = Tierlist_Decider(items, p=0.3, alpha = 0.3)\n",
    "decider = Objective_Function(items, ground_truth)\n",
    "\n",
    "budget = 24\n",
    "n_subsets = 5\n",
    "\n",
    "data = {\n",
    "    \"budget\":[],\n",
    "    \"theta_definition\":[],\n",
    "    \"theta_operator\":[],\n",
    "    \"n_theta_min\":[],\n",
    "    \"n_preferences\":[],\n",
    "    \"additivity\":[],\n",
    "    \"size\":[],\n",
    "    \"sizes_sum\":[],\n",
    "    \"time\":[],\n",
    "    \"C\":[],\n",
    "    \"W\":[],\n",
    "    \"T\":[],\n",
    "}\n",
    "\n",
    "contradictions_data = {\n",
    "    \"theta_1\":[],\n",
    "    \"theta_2\":[],\n",
    "    \"union_per_intersection\":[]\n",
    "}\n",
    "\n",
    "for repetition in range(10):\n",
    "\n",
    "    for b in range(budget):\n",
    "        s = sample_subset(items)\n",
    "        while s in decider.saved:\n",
    "            s = sample_subset(items)\n",
    "            \n",
    "        decider(s)\n",
    "        prf = decider.relation()\n",
    "        if len(prf) == 0:\n",
    "            continue\n",
    "            \n",
    "        t_heuristic = build_approx_theta(prf, [EMPTY_SET])\n",
    "            \n",
    "        ti_lex_2 = time.time()\n",
    "        t_lex2 = get_kernels_lex2(prf, get_all_k_sets(items, len(items)))\n",
    "        ti_lex_2 = time.time() - ti_lex_2\n",
    "        \n",
    "        t_lex2_rnd = random.choice(t_lex2)\n",
    "        t_lex2_union = union(t_lex2)\n",
    "        \n",
    "        \n",
    "        ti_lex_3 = time.time()\n",
    "        t_lex3 = get_kernels_lex3(prf, get_all_k_sets(items, len(items)))\n",
    "        ti_lex_3 = time.time() - ti_lex_3\n",
    "        \n",
    "        t_lex3_rnd = random.choice(t_lex3)\n",
    "        t_lex3_union = union(t_lex3)\n",
    "        \n",
    "        \n",
    "        ti_var = time.time()\n",
    "        t_var = get_kernels_variance(prf, get_all_k_sets(items, len(items)))\n",
    "        ti_var = time.time() - ti_var\n",
    "        \n",
    "        t_var_rnd = random.choice(t_var)\n",
    "        t_var_union = union(t_var)\n",
    "        \n",
    "        print(f\"Lex2 took {ti_lex_2:.2f}\")\n",
    "        print(f\"Lex3 took {ti_lex_3:.2f}\")\n",
    "        print(f\"Var took {ti_var:.2f}\")\n",
    "\n",
    "\n",
    "        for s_rep in range(5):\n",
    "            print(f\"repetition = {repetition}, b = {b}, srep = {s_rep}, npref = {len(prf)}\")\n",
    "            test_subsets = sample_subsets(items, n_subsets=n_subsets)\n",
    "            \n",
    "            \n",
    "\n",
    "            #print(f\"t_union = {t_union}, t_heuristic = {t_heuristic}, t_mins = {t_mins}, t_random = {t_random}\")\n",
    "            \n",
    "            prf_t_heuristic = predict_from_theta(t_heuristic, prf, test_subsets)\n",
    "\n",
    "            \n",
    "            prf_tlex2_union = predict_from_theta(t_lex2_union, prf, test_subsets)\n",
    "            prf_tlex2_rnd = predict_from_theta(t_lex2_rnd, prf, test_subsets)\n",
    "            prf_tlex2_all = predict_from_mult_thetas(t_lex2, prf, test_subsets)\n",
    "            \n",
    "            prf_tlex3_union = predict_from_theta(t_lex3_union, prf, test_subsets)\n",
    "            prf_tlex3_rnd = predict_from_theta(t_lex3_rnd, prf, test_subsets)\n",
    "            prf_tlex3_all = predict_from_mult_thetas(t_lex3, prf, test_subsets)\n",
    "            \n",
    "            prf_var_union = predict_from_theta(t_var_union, prf, test_subsets)\n",
    "            prf_var_rnd = predict_from_theta(t_var_rnd, prf, test_subsets)\n",
    "            prf_var_all = predict_from_mult_thetas(t_var, prf, test_subsets)\n",
    "\n",
    "            \n",
    "            C_t_heuristic, W_t_heuritistic, T_t_heuristic = ACR(prf_t_heuristic, ground_truth)\n",
    "            \n",
    "            C_tlex2_union, W_tlex2_union, T_tlex2_union = ACR(prf_tlex2_union, ground_truth)\n",
    "            C_tlex2_rnd, W_tlex2_rnd, T_tlex2_rnd = ACR(prf_tlex2_rnd, ground_truth)\n",
    "            C_tlex2_all, W_tlex2_all, T_tlex2_all = ACR(prf_tlex2_all, ground_truth)\n",
    "            \n",
    "            C_tlex3_union, W_tlex3_union, T_tlex3_union = ACR(prf_tlex3_union, ground_truth)\n",
    "            C_tlex3_rnd, W_tlex3_rnd, T_tlex3_rnd = ACR(prf_tlex3_rnd, ground_truth)\n",
    "            C_tlex3_all, W_tlex3_all, T_tlex3_all = ACR(prf_tlex3_all, ground_truth)\n",
    "            \n",
    "            C_var_union, W_var_union, T_var_union = ACR(prf_var_union, ground_truth)\n",
    "            C_var_rnd, W_var_rnd, T_var_rnd = ACR(prf_var_rnd, ground_truth)\n",
    "            C_var_all, W_var_all, T_var_all = ACR(prf_var_all, ground_truth)\n",
    "            \n",
    "            ###LEX 2\n",
    "            data[\"budget\"].append(b) \n",
    "            data[\"theta_definition\"].append(\"LEX2\")\n",
    "            data[\"theta_operator\"].append(\"UNION\")\n",
    "            data[\"time\"].append(ti_lex_2)\n",
    "            data[\"n_theta_min\"].append(len(t_lex2))\n",
    "            data[\"n_preferences\"].append(len(prf))\n",
    "            data[\"additivity\"].append(additivity(t_lex2_union))\n",
    "            data[\"size\"].append(len(t_lex2_union))\n",
    "            data[\"sizes_sum\"].append(sum(len(i) for i in t_lex2_union))\n",
    "            data[\"C\"].append(C_tlex2_union)\n",
    "            data[\"W\"].append(W_tlex2_union)\n",
    "            data[\"T\"].append(T_tlex2_union)\n",
    "            \n",
    "            data[\"budget\"].append(b) \n",
    "            data[\"theta_definition\"].append(\"LEX2\")\n",
    "            data[\"theta_operator\"].append(\"RND\")\n",
    "            data[\"time\"].append(ti_lex_2)\n",
    "            data[\"n_theta_min\"].append(len(t_lex2))\n",
    "            data[\"n_preferences\"].append(len(prf))\n",
    "            data[\"additivity\"].append(additivity(t_lex2_rnd))\n",
    "            data[\"size\"].append(len(t_lex2_rnd))\n",
    "            data[\"sizes_sum\"].append(sum(len(i) for i in t_lex2_rnd))\n",
    "            data[\"C\"].append(C_tlex2_rnd)\n",
    "            data[\"W\"].append(W_tlex2_rnd)\n",
    "            data[\"T\"].append(T_tlex2_rnd)\n",
    "            \n",
    "            data[\"budget\"].append(b) \n",
    "            data[\"theta_definition\"].append(\"LEX2\")\n",
    "            data[\"theta_operator\"].append(\"ALL\")\n",
    "            data[\"time\"].append(ti_lex_2)\n",
    "            data[\"n_theta_min\"].append(len(t_lex2))\n",
    "            data[\"n_preferences\"].append(len(prf))\n",
    "            data[\"additivity\"].append(additivity(t_lex2[0]))\n",
    "            data[\"size\"].append(len(t_lex2[0]))\n",
    "            data[\"sizes_sum\"].append(sum(len(i) for i in t_lex2[0]))\n",
    "            data[\"C\"].append(C_tlex2_all)\n",
    "            data[\"W\"].append(W_tlex2_all)\n",
    "            data[\"T\"].append(T_tlex2_all)\n",
    "            \n",
    "            \n",
    "            ####LEX 3 \n",
    "            data[\"budget\"].append(b) \n",
    "            data[\"theta_definition\"].append(\"LEX3\")\n",
    "            data[\"theta_operator\"].append(\"UNION\")\n",
    "            data[\"time\"].append(ti_lex_3)\n",
    "            data[\"n_theta_min\"].append(len(t_lex3))\n",
    "            data[\"n_preferences\"].append(len(prf))\n",
    "            data[\"additivity\"].append(additivity(t_lex3_union))\n",
    "            data[\"size\"].append(len(t_lex3_union))\n",
    "            data[\"sizes_sum\"].append(sum(len(i) for i in t_lex3_union))\n",
    "            data[\"C\"].append(C_tlex3_union)\n",
    "            data[\"W\"].append(W_tlex3_union)\n",
    "            data[\"T\"].append(T_tlex3_union)\n",
    "            \n",
    "            data[\"budget\"].append(b) \n",
    "            data[\"theta_definition\"].append(\"LEX3\")\n",
    "            data[\"theta_operator\"].append(\"RND\")\n",
    "            data[\"time\"].append(ti_lex_3)\n",
    "            data[\"n_theta_min\"].append(len(t_lex3))\n",
    "            data[\"n_preferences\"].append(len(prf))\n",
    "            data[\"additivity\"].append(additivity(t_lex3_rnd))\n",
    "            data[\"size\"].append(len(t_lex3_rnd))\n",
    "            data[\"sizes_sum\"].append(sum(len(i) for i in t_lex3_rnd))\n",
    "            data[\"C\"].append(C_tlex3_rnd)\n",
    "            data[\"W\"].append(W_tlex3_rnd)\n",
    "            data[\"T\"].append(T_tlex3_rnd)\n",
    "            \n",
    "            data[\"budget\"].append(b) \n",
    "            data[\"theta_definition\"].append(\"LEX3\")\n",
    "            data[\"theta_operator\"].append(\"ALL\")\n",
    "            data[\"time\"].append(ti_lex_3)\n",
    "            data[\"n_theta_min\"].append(len(t_lex3))\n",
    "            data[\"n_preferences\"].append(len(prf))\n",
    "            data[\"additivity\"].append(additivity(t_lex3[0]))\n",
    "            data[\"size\"].append(len(t_lex3[0]))\n",
    "            data[\"sizes_sum\"].append(sum(len(i) for i in t_lex3[0]))\n",
    "            data[\"C\"].append(C_tlex3_all)\n",
    "            data[\"W\"].append(W_tlex3_all)\n",
    "            data[\"T\"].append(T_tlex3_all)\n",
    "            \n",
    "            \n",
    "            ####VARIANCE  \n",
    "            data[\"budget\"].append(b) \n",
    "            data[\"theta_definition\"].append(\"VAR\")\n",
    "            data[\"theta_operator\"].append(\"UNION\")\n",
    "            data[\"time\"].append(ti_var)\n",
    "            data[\"n_theta_min\"].append(len(t_var))\n",
    "            data[\"n_preferences\"].append(len(prf))\n",
    "            data[\"additivity\"].append(additivity(t_var_union))\n",
    "            data[\"size\"].append(len(t_var_union))\n",
    "            data[\"sizes_sum\"].append(sum(len(i) for i in t_var_union))\n",
    "            data[\"C\"].append(C_var_union)\n",
    "            data[\"W\"].append(W_var_union)\n",
    "            data[\"T\"].append(T_var_union)\n",
    "            \n",
    "            data[\"budget\"].append(b) \n",
    "            data[\"theta_definition\"].append(\"VAR\")\n",
    "            data[\"theta_operator\"].append(\"RND\")\n",
    "            data[\"time\"].append(ti_var)\n",
    "            data[\"n_theta_min\"].append(len(t_var))\n",
    "            data[\"n_preferences\"].append(len(prf))\n",
    "            data[\"additivity\"].append(additivity(t_var_rnd))\n",
    "            data[\"size\"].append(len(t_var_rnd))\n",
    "            data[\"sizes_sum\"].append(sum(len(i) for i in t_var_rnd))\n",
    "            data[\"C\"].append(C_var_rnd)\n",
    "            data[\"W\"].append(W_var_rnd)\n",
    "            data[\"T\"].append(T_var_rnd)\n",
    "            \n",
    "            data[\"budget\"].append(b) \n",
    "            data[\"theta_definition\"].append(\"VAR\")\n",
    "            data[\"theta_operator\"].append(\"ALL\")\n",
    "            data[\"time\"].append(ti_var)\n",
    "            data[\"n_theta_min\"].append(len(t_var))\n",
    "            data[\"n_preferences\"].append(len(prf))\n",
    "            data[\"additivity\"].append(additivity(t_var[0]))\n",
    "            data[\"size\"].append(len(t_var[0]))\n",
    "            data[\"sizes_sum\"].append(sum(len(i) for i in t_var[0]))\n",
    "            data[\"C\"].append(C_var_all)\n",
    "            data[\"W\"].append(W_var_all)\n",
    "            data[\"T\"].append(T_var_all)\n",
    "            \n",
    "            df = pd.DataFrame(data)\n",
    "            df.to_csv(\"theta_definitions_comparisons_2.csv\")\n",
    "            #print(df)\n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1217de0c-6055-4dce-9bd6-3157b6db9f1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6578ad-75bf-4e3a-a780-8ee721643dc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
